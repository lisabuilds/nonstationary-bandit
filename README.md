# Nonstationary Bandit Simulation and Deep Performance Analysis

This project compares several bandit algorithms on a nonstationary 10-armed bandit problem. The following animations illustrate the evolution of key performance metrics over time.

## Metrics


| Average Reward | % Optimal Action |
| -------------- | ---------------- |
| ![Average Reward](animation_avg_rewards.gif) | ![Optimal Action](animation_opt_perc.gif) |

| Cumulative Reward | Instantaneous Regret | Reward Variance |
| ----------------- | -------------------- | --------------- |
| ![Cumulative Reward](animation_cum_rewards.gif) | ![Instantaneous Regret](animation_inst_regret.gif) | ![Reward Variance](animation_reward_var.gif) |
